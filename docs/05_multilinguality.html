<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Multilingual Linguistic Data Science</title><link rel="stylesheet" href="dist/reset.css"><link rel="stylesheet" href="dist/reveal.css"><link rel="stylesheet" href="dist/theme/beige.css"><link rel="stylesheet" href="plugin/highlight/monokai.css"><style>.vertical-center {
  margin: 0;
  position: absolute;
  top: 50%;
  -ms-transform: translateY(-50%);
  transform: translateY(-50%);
}
.tag { padding-left:10px; padding-right:10px;margin-right:2px;border-radius:6px;} 
.blue { background-color: mediumblue; color: white; }
.pink { background-color: hotpink; color: white; }
.green { background-color: seagreen; color: white; }
.yellow { background-color: goldenrod; color: white; }
</style><div class="reveal"><div class="slides"><section data-background-image="img/multilingual1.png" data-background-opacity="0.5"><h1>Multilinguality</h1><h3>John P. McCrae - University of Galway</h3><h5>Course at ESSLLI 2024</h5><img src="img/uog.svg" style="position:absolute;left:70%;top:110%;width:500px;"></section><section data-background-image="img/machine_translation.png" data-background-opacity="0.5" data-background-position="top"><h1>Machine Translation</h1></section><section><h2>History of Machine Translation</h2><ul><li>1954 Georgetown-IBM experiment</li><li>1966 ALPAC report</li><li>1970s-1980s: Rule-based MT</li><li>1993 Statistical MT (IBM/Brown)</li><li>2000s: Statistical MT (Och/Koehn)</li><li>2014 Neural MT (Google)</li></ul></section><section data-background-image="img/google_translate.png" data-background-opacity="0.5"><h2>Machine Translation</h2><p>Market dominated by Google, Microsoft, Amazon</p><p>Open-source alternatives: Moses, Marian, OpenNMT</p><p>Some special-purpose systems: Apertium, Joshua</p></section><section><h2>Computer-Aided Translation</h2><ul><li>Translation Memory</li><li>Translation suggestions</li><li>Quality estimation</li><li>Post-editing</li></ul></section><section><h2>Bilingual Communication</h2><ul><li>Translation</li><li>Interpreting</li><li>Multilingual communication</li></ul><p>Still very challenging</p></section><section data-background-image="img/translation_error_2.jpeg"></section><section data-background-image="img/translation_error_3.jpg"></section><section data-background-image="img/translation_error_1.webp"></section><section data-background-image="img/translation_error_4.jpg"></section><section><h2>Why is MT so hard?</h2><ul><li>Translation depends on context</li><ul><li>"Black Eye" is "<span style="color:blue;">blaues</span> Auge" (<em>blue eye</em>) in German and "ojo <span style="color:violet">morado</span>" (<em>violet eye </em>) in Spanish</li></ul><li>Subtle difference matter</li><ul><li>"value" can mean "worth", "price" or "importance" in different contexts</li></ul></ul></section><section><h2>Reordering</h2><img src="img/jap_reordering1.svg"></section><section><h2>Reordering</h2><img src="img/jap_reordering2.svg"></section><section><h2>Long-distance dependencies</h2><ul><li>English: I saw the <span style="color:hotpink">movie</span> and <span style="color:mediumblue">it<span> was great!</li><li class="fragment">German: Ich sah <span style="color:hotpink">den Film</span> und <span style="color:mediumblue">er (he)</span> was prima!</li><li class="fragment">Spanish: Vi <span style="color:hotpink">la película</span> y <span style="color:mediumblue">ella (she)</span> fue súper!</li></ul></section><section><h2>Semantic issues</h2><ul><li>John liked Michael, so he<sub style="font-size:0.5em">JOHN</sub> helped him<sub style="font-size:0.5em">MICHAEL</sub></li><li>John liked Michael, as he<sub style="font-size:0.5em">MICHAEL</sub> helped him<sub style="font-size:0.5em">JOHN</sub></li></ul></section><section><h2>Missing Information in Translation</h2><ul><li>English: "Cousin"</li><li>German: "Vetter" (male) / "Cousine" (female)</li><li>Chinese:</li><table style="font-size:0.5em"><tr><td style="width:6em">堂兄 / 堂哥</td><td>elder</td><td>father's brother's son</td><td style="width:6em"> 表兄 /  表哥</td><td>elder</td><td>mother's sibling's or father's sister's son</td></tr><tr><td> 堂弟</td><td>younger</td><td>father's brother's son</td><td> 表弟</td><td>younger</td><td>mother's sibling's or father's sister's son</td></tr><tr><td> 堂姐 / 堂姊</td><td>elder</td><td>father's brother's daughter</td><td> 表姐 /  表姊</td><td>elder</td><td>mother's sibling's or father's sister's daughter</td></tr><tr><td> 堂妹</td><td>younger</td><td>father's brother's daughter</td><td> 表妹</td><td>younger</td><td>mother's sibling's or father's sister's daughter</td></tr></table></ul></section><section><h1>Buzz Group</h1><p>Why is translation hard in your language?</p></section><section><h2>Under-resourced Languages</h2><div style="width:40%;float:left"><ul><li>7,000 languages world wide</li><li>Google Translates supports ~100 languages</li><li>Wikipedia exists for ~300 languages</li><li>Even for those (e.g., Irish) translation is significantly worse</li></ul></div><div style="width:60%;float:left;"><img src="img/adela-map.svg"></div></section><section><h2>Phrase-based MT</h2><img src="img/phrase_mt.svg" style="width:80%"></section><section><h2>Neural MT</h2><img src="img/neural_mt.svg"></section><section><h2>Prompt-based MT</h2><img src="img/chatgpt_translate.png"></section><section data-background-image="img/celtic_robot.png" data-background-opacity="0.5" data-background-position="top"><h1>Under-resourced Languages</h1></section><section><h2>What is under-resourced?</h2><img src="img/def_underresourced.svg"></section><section><h2>Parallel Corpora</h2><img src="img/parallel_corpora_chart.svg"></section><section><h2>Transfer Learning</h2><img src="img/mt_transfer.svg"></section><section><h2>Translation-based Transfer Learning</h2><img src="img/translate_transfer.svg"></section><section><h2>Parameter-sharing Transfer Learning</h2><img src="img/transfer_learning2.svg" width="60%"></section><section><h2>Language Adapters</h2><img src="img/language_adapters.png" width="60%"><small>Source: Rathnayake et al., Adapter-based fine-tuning of pre-trained multilingual language models for code-mixed and code-switched text classification</small></section><section><h1>Code-mixing and Language Identification</h1></section><section><h2>Code-mixing, switching</h2><ul><li>Extremely common in multilingual communities, especially online (3.5% of all tweets)</li><li>Code-mixing: Matrix language with insertions from other languages (often English)</li><li>Code-switching: changing between languages</li><li>Loanwords: words from other languages (understandable to speakers without knowledge of the other language)</li></ul></section><section><h2>Challenges for code-mixed language</h2><ul><li>Lack of data; most text is from noisy sources</li><li>Many combinations of languages</li><li>How to apply monolingual trained models to code-mixed texts?</li></ul></section><section><h2>Methods for code-mixed language</h2><ul><li>Supervised learning (from scratch)</li><li>Divide-and-conquer</li><li>Translate to matrix language</li><li>Zero-shot approach</li></ul></section><section><h1>Hands-on: Language Identification</h1></section><section data-background-image="img/distant_reading.png" data-background-opacity="0.5"><h1>Distant Reading</h1></section><section><h2>Close vs Distance Reading</h2><ul><li>Close reading is the traditional way of reading a text</li><li>Distant reading uses computational methods to analyse canons of text</li><li>Term attributed to Franco Moretti (2000)</li></ul><p style="font-size:0.7em;">"So far as the engines of history are concerned, meaning does not matter. In principle, one could study the history of a literary tradition without reading any of literature. ... the main virtue of the computerized content analysis methods I use is that they save one from actually having to read the literature" - Martindale</p></section><section><h2>"The Great Unread"</h2><ul><li>Thousands of books published in 19th century England</li><li>Only a few studied now by famous authors</li><li>Computational techniques can reveal trends</li><ul><li>Titles became shorter</li><li>Text became less abstract</li></ul></ul></section><section><h4>Analysis methods for Distant Reading - Diachronic Frequency Analysis</h4><img src="img/presidents_freq.png" width="65%"><small>Source: Figure 1.4.1 – The Atlantic’s “The Language of the State of the Union” © Benjamin Schmidt, Mitch Fraa, Chris Barna, Libby Bawcombe, Noah Gordon, Betsy Ebersole, Jennie Rothenberg Gritz </small></section><section><h4>Analysis methods for Distant Reading - Lexical Diversity</h4><img src="img/hip_hop_vocab.png" width="90%"><small>Source: Matt Daniels</small></section><section><h4>Analysis methods for Distant Reading - Topic Modelling</h4><img src="img/topic_modelling.png"></section><section><h2>Narrative Analysis</h2><ul><li>Content (topics, characters, events, ...)</li><li>Structure (plot, character relationsships, ...)</li><li>Discourse (narrator, style, ...)</li></ul><p>Approach: collect text, annotate, analyse</p></section><section><h1>Summary</h1></section><section><h2>Summary</h2><ul><li><a href="https://slator.com/yes-now-they-claim-machines-outperform-human-translation-in-adequacy/">Is machine translation solved?</a></li><li>Still a challenge for <b>most</b> of the world's languages</li><li>Next billion internet users will speak even more languages</li></ul></section><section><h2>Thank you for attending the course!</h2><p>Feel free to contact me at <a href="mailto:john@mccr.ae">john@mccr.ae</a> if you have any questions</p><small> <a href="index.html">Back</a></small></section></div></div><script src="dist/reveal.js"></script><script src="plugin/notes/notes.js"></script><script src="plugin/markdown/markdown.js"></script><script src="plugin/highlight/highlight.js"></script><script src="plugin/math/math.js"></script><script>// More info about initialization & config:
// - https://revealjs.com/initialization/
// - https://revealjs.com/config/
Reveal.initialize({
        hash: true,
        slideNumber: true,

        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath ]
});</script></head></html>