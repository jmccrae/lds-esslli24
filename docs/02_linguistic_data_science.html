<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Linguistic Data Science</title><link rel="stylesheet" href="dist/reset.css"><link rel="stylesheet" href="dist/reveal.css"><link rel="stylesheet" href="dist/theme/beige.css"><link rel="stylesheet" href="plugin/highlight/monokai.css"><style>.flcont {
    border: 1px solid #DDDDDD;
    width: 200px;
    height: 200px;
    position:relative;
}
.floating {
    float: left;
    position: absolute;
    left: 0px;
    top: 0px;
    background-color: grey;
}</style></head><body><div class="reveal"><div class="slides"><section data-background-image="img/linguistic_data_science_0.png" data-background-opacity="0.5"><h1>Linguistic Data Science</h1><h3>John P. McCrae - University of Galway</h3><h5>Course at ESSLLI 2024</h5><img src="img/uog.svg" style="float:left;position:absolute;left:70%;width:450px;"></section><section data-background-image="img/corpus.png" data-background-opacity="0.5"><h1>Corpora and Data</h1></section><section><h2>Types of Linguistic Data</h2><ul> <li>Corpora - collections of texts</li><li>Lexicons - information about words</li><li>Knowledge bases - structured information about the world</li><li>Typological databases - information about languages</li></ul></section><section><h2>Plain-text Corpora</h2><ul><li>Sources such as <a href="https://www.gutenberg.org/" target="_blank">Project Gutenberg</a>, <a href="https://en.wikipedia.org" target="_blank">Wikipedia</a></li><li>Curated corpora such as <a href="http://www.natcorp.ox.ac.uk/" target="_blank">British National Corpus</a> and <a href="https://anc.org/" target="_blank">Open American National Corpus</a></li><li>Massive web corpora such as <a href="https://github.com/allenai/allennlp/discussions/5056" target="_blank">C4</a></li><ul><li>300GB of English data, 9.7TB total!</li></ul></ul></section><section><h2>Annotated Corpora</h2><ul><li>Corpora with syntactic, semantic and other annotations</li><li><a href="https://universaldependencies.org/">Universal Dependencies</a></li><li><a href="https://catalog.ldc.upenn.edu/LDC2019T13">Penn Treebank</a></li><li><a href="https://catalog.ldc.upenn.edu/LDC2015T13">PropBank</a></li></ul></section><section><h2>Universal Dependencies</h2><table style="font-size: 0.5em"><tr><th>ID</th><th>Form</th><th>Lemma</th><th>UPOS</th><th>XPOS</th><th>Head</th><th>Dep</th></tr><tr><td>1	</td><td>The	</td><td>the	</td><td>DET	</td><td>Definite=Def|PronType=Art	</td><td>2	</td><td>det</td></tr><tr><td>2	</td><td>prevalence	</td><td>prevalence	</td><td>NOUN	</td><td>Number=Sing	</td><td>0	</td><td>root	</td></tr><tr><td>3	</td><td>of	</td><td>of	</td><td>ADP	</td><td>_	</td><td>4	</td><td>case</td></tr><tr><td>4	</td><td>discrimination	</td><td>discrimination	</td><td>NOUN	</td><td>Number=Sing	</td><td>2	</td><td>nmod</td></tr><tr><td>5	</td><td>across	</td><td>across	</td><td>ADP	</td><td>_	</td><td>7	</td><td>case</td></tr><tr><td>6	</td><td>racial	</td><td>racial	</td><td>ADJ	</td><td>Degree=Pos	</td><td>7	</td><td>amod</td></tr><tr><td>7	</td><td>groups	</td><td>group	</td><td>NOUN	</td><td>Number=Plur	</td><td>2	</td><td>nmod</td></tr><tr><td>8	</td><td>in	</td><td>in	</td><td>ADP	</td><td>_	</td><td>10	</td><td>case</td></tr><tr><td>9	</td><td>contemporary	</td><td>contemporary	</td><td>ADJ	</td><td>Degree=Pos	</td><td>10	</td><td>amod</td></tr><tr><td>10	</td><td>America	</td><td>America	</td><td>PROPN	</td><td>Number=Sing	</td><td>2	</td><td>nmod</td></tr></table></section><section><h2>Parallel Corpora</h2><ul><li><a href="https://opus.nlpl.eu/" target="_blank">OPUS</a> - many languages</li><li><a href="https://www.statmt.org/europarl/" target="_blank">Europarl</a> - 21 languages</li><li><a href="https://www.statmt.org/wmt20/" target="_blank">WMT</a> - 100+ languages</li></ul></section><section><h2>Parallel Corpus Example</h2><table style="font-size: 0.5em"><tr><th>English</th><th>Irish</th></tr><tr><td>Monitoring of the Implementation of Certain Commitments in your Language Scheme </td><td>Tag: faireachÃ¡n ar chur i bhfeidhm gealltanais Ã¡irithe de bhur scÃ©im teanga</td></tr><tr><td>Hope you are keeping well.</td><td>Beatha agus SlÃ¡inte.</td></tr><tr><td>Thank you for your co-operation on this matter. </td><td>Gabhaim buÃ­ochas leat as ucht do chomhoibriÃº ar an Ã¡bhar seo.</td></tr><tr><td>Kind regards, </td><td>Is mise, le meas, _______________ </td></tr></table></section><section><h2>Lexicons</h2><ul><li><a href="https://en-word.net" target="_blank">Open English WordNet</a> - English</li><li><a href="https://babelnet.org/" target="_blank">BabelNet</a> - 271 languages</li><li><a href="https://framenet.icsi.berkeley.edu/fndrupal/" target="_blank">FrameNet</a> - English</li></ul></section><section><h2>Knowledge Bases</h2><ul><li><a href="https://www.wikidata.org/" target="_blank">Wikidata</a></li><li><a href="https://www.dbpedia.org/" target="_blank">DBPedia</a></li><li>Many specific knowledge bases</li></ul></section><section><h2>Typologies</h2><ul><li><a href="https://wals.info/" target="_blank">World Atlas of Language Structures</a></li></ul></section><section data-background-image="img/corpus_selection.png" data-background-opacity="0.5"><h1>Corpus Selection and Construction</h1></section><section><h2>Corpus linguistics</h2><p>Analysis of corpus reveals hidden patterns in language</p><p>New tools allow us to find new information hidden in the corpus</p></section><section data-background-image="img/firth.png" data-background-opacity="0.5"><h2>Collocations</h2><p>Collocations are words that occur together</p><p>Firth: "You shall know a word by the company it keeps"</p></section><section><h2>Corpus selection</h2><div style="width:50%;float:left"><ul><li>Spoken/written</li><li>Dialect</li><li>Genre</li></ul></div><div style="width:50%;float:right"><ul><li>Time period</li><li>Size</li><li>Multimodality</li></ul></div></section><section><h2>Corpus annotations</h2><ul><li>Syntactic annotations</li><li>Semantic annotations (e.g., word senses)</li><li>Classifications (e.g., sentiment)</li><li>Parallel texts</li></ul></section><section><h2>Specialized corpora</h2><ul><li>Learner corpora</li><li>Historical corpora</li><li>Noisy user-generated text</li></ul></section><section data-background-image="img/morphology.png" data-background-opacity="0.5"><h1>Types, tokens and morphology</h1></section><section><h2>Types and tokens</h2><ul><li><b>Tokens</b> refer to the individual words in the text</li><li><b>Types</b> are the distinct words we see in the text</li></ul><div class="center"><p> <em>I know that this is simple</em></p><p>6 <b>Tokens</b>, 5 <b>Types</b></p></div></section><section><h2>Tokenization</h2><img src="img/tokenization.svg"><small>Source: https://spacy.io/usage/spacy-101</small></section><section><h2>Non-linguistic tokens</h2><ul><li>Hashtags/mentions (#amazing, @john)</li><li>URLs</li><li>Emoticons (:-O, ðŸ˜€)</li></ul></section><section><h2>Compounds</h2><ul><li><i>bookshelves</i>, <i>bedroom</i>, <i>policeman</i></li><li><i>Flachbildschirmfernseher</i> (German: flat screen TV)</li><li><i>bestuurdersaansprakelijkheidsverzekering</i> (Dutch: drivers' liability insurance)</li></ul></section><section data-background-image="img/asian_languages.svg" data-background-opacity="0.5"><h2>Tokenization in Asian Languages</h2><ul><li>Chinese, Japanese and Thai do not use spaces at all</li><li>Other languages (Vietnamese, Tibetan, ...) space every syllable</li><li>Tokenization for these languages is non-trivial</li></ul></section><section><h2>Aside: What is a word?</h2><ul><li>Occurs between spaces (and punctuation)</li><li>Can be a single utterance</li><li>Has a distinct meaning</li><li>Syntactically free</li><li>Has an inflectional paradigm (e.g., plural, past tense, genitive case)</li><li>(Useful as a) headword in a dictionary</li></ul><p>Mostly overlapping definitions!</p></section><section><h2>Subword tokenization</h2><p>Maybe a human definition of word is not the best?</p><pre><code>Super ##cali ##frag ##il ##istic ##ex ##pi ##ali ##do ##cious</code></pre></section><section><h2>WordPiece (Wu et al., 2016)</h2><ol> <li>Initially use only characters as words</li><li>Build a probability model on the corpus</li><li>Merge two most probable words</li><li>Repeat until limit of words is reached of likelihood is below a threshold</li></ol></section><section><h2>Morphology</h2><ul><li><b>Lemmatization</b>: Reduce words to their base form</li><li><b>Stemming</b>: Reduce words to their stem</li></ul></section><section><h2>Morphology Examples</h2><table><tr><th>Word</th><th>Lemma</th><th>Stem</th></tr><tr><th>cars</th><th>car</th><th>car</th></tr><tr><th>caring</th><th>care</th><th>car</th></tr><tr><th>taught</th><th>teach</th><th>taught (!?)</th></tr></table><p>Stemming is not linguistically motivated</p></section><section><h2>Inflection and Derivation</h2><ul> <li>Inflection captures the lemma and the change that has happened to it</li><ul><li>writing = write + PRESENT + PROGRESSIVE</li></ul><li>Derivation is how new words are formed</li><ul><li>agreement = agree + MENT</li></ul></ul></section><section><h2>Morphological Analysis</h2><ul><li>English is <em>quite</em> simple</li><li>Some languages (Chinese, ...) have no morphology</li><li>In other languages <b>one</b> word can be a whole sentence</li><p>ÙˆØ³ÙŠÙƒØªØ¨ÙˆÙ†Ù‡Ø§ /wasayaktubuwnahA/ 'and they will write it'</p></ul></section><section><h1>Example: English Clitics</h1></section><section><h2>Example: English Clitics</h2><ul> <li>Clitics are words that are pronounced as part of another word</li><li>In particular we will look at <em>n't</em> </li><li>Does the use of more clitics indicate a more informal text?</li></ul></section><section data-background-image="img/social_media_1.png" data-background-opacity="0.5"><h1>Social Media Analytics</h1></section><section><h2>Social Media - Enterprise</h2><img src="img/twitter_sentiment.webp"><small>Image source: https://monkeylearn.com/blog/sentiment-analysis-of-twitter/ </small></section><section><h2>Social Media - Politics</h2><img src="img/elections.jpg" width="70%"><small>Image source: https://www.forbes.com/sites/waynerash/2020/09/29/new-big-data-sentiment-analysis-show-potential-biden-election-landslide/</small></section><section><h2>Ethical Data Collection</h2><ul><li>Copyright</li><li>Data Protection/Privacy</li><li>Bias (gender, race, sexuality, ...)</li><li>Represntativeness</li></ul></section><section><h2>Data Collection</h2><ul><li>API</li><li>Web Scraping</li><li>Crowdsourcing</li><li>Data Purchase</li></ul></section><section><h2>Noisy User-Generated Content</h2><ul><li>Spelling</li><li>Grammar</li><li>Slang</li><li>Emojis</li><li>Code-mixing</li></ul></section><section data-background-image="img/emotions.png" data-background-opacity="0.5"><h1>Sentiment, Emotion, Sarcasm</h1></section><section><h2>Sentiment Analysis</h2><ul><li>Predicting sentiment of text</li><li>Binary (positive/negative) or graded (0-5)</li></ul></section><section><h2>Challenges of Sentiment Analysis</h2><ul><li>Indirectness: "Although the product is disliked by many, it is still popular"</li><li>Ambiguity: "The concert was crazy" vs. "The traffic was crazy"</li><li>Irony: "I love it when my flight is delayed"</li><li>Negation: "I don't like it"</li></ul></section><section><h2>Lexicon Approaches</h2><p>Generate a lexicon of positive and negative words</p><p>Use counts to evaluate sentiment</p><table><tr><th>Positive</th><th>Negative</th></tr><tr><td>good</td><td>bad</td></tr><tr><td>great</td><td>terrible</td></tr><tr><td>excellent</td><td>awful</td></tr><tr><td>...</td><td>...</td></tr></table></section><section><h2>SentiWordNet</h2><img src="img/sentiwordnet.png"></section><section><h2>Machine Learning Approaches - Features</h2><ul><li>Sentiment features (sentiment lexicon)</li><li>Linguistic features (n-grams, ...)</li><li>Social Media features (hashtags, emoticons, â€¦)</li><li>Other features (negation)</li><li>Feature selection and weighting (occurrence (binary), freq, PMI, TF-IDF)</li></ul></section><section><h2>Machine Learning Approaches - Deep Learning</h2><ul><li>Deep neural networks (LSTM, transformer, ...)</li><li>Pre-trained Language Models</li><li>Prompt-based Learning</li></ul></section><section><h2>Aspect-Based Sentiment Analysis</h2><p>"The cameraâ€™s focus was bad, but has a great size and is easy-to-use."</p><p>Aspects:</p><ul><li>Focus (negative)</li><li>Size (positive)</li><li>Ease-of-use (positive)</li></ul></section><section><h2>Emotion Analysis</h2><ul style="font-size:0.9em"><li>Emotion</li><ul><li>angry, sad, joyful, fearful, ashamed, proud, elated</li></ul><li>Mood</li><ul><li>cheerful, gloomy, irritable, listless, depressed, buoyant</li></ul><li>Interpersonal stances</li><ul><li>friendly, flirtatious, distant, cold, warm, supportive, contemptuous</li></ul><li>Attitudes</li><ul><li>liking, loving, hating, valuing, desiring</li></ul><li>Personality traits</li><ul><li>nervous, anxious, reckless, morose, hostile, jealous</li></ul></ul></section><section><h2>Emotion models - Ekman</h2><img src="img/ekman.jpg" width="50%"><small>Source: https://sites.tufts.edu/emotiononthebrain/2014/12/08/am-i-in-trouble-interpreting-facial-expressions/</small></section><section><h2>Emotion models - Plutchik</h2><div><img src="img/plutchik.webp" width="50%"></div><small>Source: Machine Elf 1735 (public domain)</small></section><section><h2>Emotion models - LÃ¶vheim (VAD)</h2><img src="img/vad.jpg" width="50%"><small>Source: Mitrut et al. (2019) Emotion Classification Based on Biophysical Signals and Machine Learning Techniques</small></section><section><h1>Hands-on: Sarcasm Detection</h1></section><section data-background-image="img/linguistic_data_science_1.png" data-background-opacity="0.5"><h1>Summary</h1></section><section><h2>Summary</h2><ul><li>Corpora, lexicons, knowledge bases, typologies are the main types of linguistic data</li><li>Sourcing and processing textual data is a key challenge</li><li>Sentiment analysis is a natural application of linguistic data science</li></ul><small> <a href="index.html">Back</a></small></section></div></div><script src="dist/reveal.js"></script><script src="plugin/notes/notes.js"></script><script src="plugin/markdown/markdown.js"></script><script src="plugin/highlight/highlight.js"></script><script>// More info about initialization & config:
// - https://revealjs.com/initialization/
// - https://revealjs.com/config/
Reveal.initialize({
        hash: true,
        slideNumber: true,

        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
});</script></body></html>